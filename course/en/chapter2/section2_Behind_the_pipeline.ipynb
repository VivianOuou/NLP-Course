{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VivianOuou/NLP-Course/blob/main/course/en/chapter2/section2_Behind_the_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4Jo7OKCEh4a"
      },
      "source": [
        "# Behind the pipeline (PyTorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvnSIyqrEh4c"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_eW0RF8hEh4d",
        "outputId": "4157eb72-60d1-4027-d4ae-36667954f7c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.11/dist-packages (4.50.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (0.5.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (0.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (5.29.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ä½¿ç”¨åˆ†è¯å™¨è¿›è¡Œé¢„å¤„ç†\n",
        "\n",
        "ä¸å…¶ä»–ç¥ç»ç½‘ç»œä¸€æ ·ï¼ŒTransformeræ¨¡å‹æ— æ³•ç›´æ¥å¤„ç†åŸå§‹æ–‡æœ¬ï¼Œå› æ­¤æµç¨‹çš„ç¬¬ä¸€æ­¥æ˜¯å°†æ–‡æœ¬è¾“å…¥è½¬æ¢ä¸ºæ¨¡å‹å¯ç†è§£çš„æ•°å­—ã€‚ä¸ºæ­¤æˆ‘ä»¬ä½¿ç”¨åˆ†è¯å™¨ï¼ˆtokenizerï¼‰ï¼Œå…¶æ ¸å¿ƒåŠŸèƒ½åŒ…æ‹¬ï¼š\n",
        "\n",
        "åˆ†è¯ï¼šå°†è¾“å…¥æ‹†åˆ†ä¸ºå•è¯ã€å­è¯æˆ–ç¬¦å·ï¼ˆå¦‚æ ‡ç‚¹ï¼‰ç­‰åŸºæœ¬å•å…ƒï¼ˆç§°ä¸ºtokenï¼‰\n",
        "æ•°å€¼æ˜ å°„ï¼šå°†æ¯ä¸ªtokenè½¬æ¢ä¸ºå¯¹åº”çš„æ•´æ•°\n",
        "é™„åŠ è¾“å…¥ï¼šæ·»åŠ æ¨¡å‹å¯èƒ½éœ€è¦çš„å…¶ä»–è¾…åŠ©ä¿¡æ¯ï¼ˆå¦‚æ³¨æ„åŠ›æ©ç ï¼‰"
      ],
      "metadata": {
        "id": "k42IpyW5F90P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "JHGOSUH0Eh4e",
        "outputId": "9543885a-f089-4052-a852-7d02cbc0df10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
              " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\n",
        "    [\n",
        "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "        \"I hate this so much!\",\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "1WuEtJJlEh4f"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "4xAdzVWPEh4f",
        "outputId": "9968f63c-9df5-474b-b5a0-0106f5566998",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
            "          2607,  2026,  2878,  2166,  1012,   102],\n",
            "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
          ]
        }
      ],
      "source": [
        "raw_inputs = [\n",
        "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "    \"I hate this so much!\",\n",
        "]\n",
        "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "åŠ è½½ä¸ä½¿ç”¨æ¨¡å‹\n",
        "\n",
        "æˆ‘ä»¬å¯ä»¥åƒä¸‹è½½åˆ†è¯å™¨ä¸€æ ·ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ã€‚ğŸ¤— Transformers æä¾›äº† AutoModel ç±»ï¼ŒåŒæ ·åŒ…å« from_pretrained() æ–¹æ³•ï¼š\n",
        "\n",
        "å¥½çš„ï¼æˆ‘ç”¨ä¸€ä¸ªæ›´ç›´è§‚çš„ä¾‹å­æ¥è§£é‡ŠTransformerè¾“å‡ºçš„ä¸‰ç»´å‘é‡ç»“æ„ï¼Œç‰¹åˆ«æ˜¯\"éšè—å¤§å°ï¼ˆHidden Sizeï¼‰\"è¿™ä¸ªå…³é”®ç»´åº¦ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "### ä»¥å…·ä½“ä¾‹å­è¯´æ˜ä¸‰ç»´è¾“å‡ºç»“æ„\n",
        "å‡è®¾æˆ‘ä»¬æœ‰ä»¥ä¸‹ä¸¤ä¸ªå¥å­ç»„æˆä¸€ä¸ªbatchï¼š\n",
        "1. \"I love NLP!\"  \n",
        "2. \"Transformers are powerful.\"\n",
        "\n",
        "ç»è¿‡åˆ†è¯å’Œå¡«å……åï¼Œæ¯ä¸ªå¥å­è¢«è½¬æ¢ä¸ºé•¿åº¦ä¸º6çš„token IDsï¼ˆå‡è®¾å¡«å……åé•¿åº¦ç»Ÿä¸€ä¸º6ï¼‰ã€‚ä½¿ç”¨ä¸€ä¸ªéšè—å±‚å¤§å°ä¸º4çš„å¾®å‹Transformeræ¨¡å‹ï¼ˆå®é™…æ¨¡å‹éšè—å±‚å¤§å¾—å¤šï¼Œè¿™é‡Œç®€åŒ–è¯´æ˜ï¼‰ï¼š\n",
        "\n",
        "#### 1. è¾“å…¥å¼ é‡å½¢çŠ¶ï¼ˆæ¨¡å‹æ¥æ”¶çš„`input_ids`ï¼‰\n",
        "```python\n",
        "shape = [batch_size, sequence_length] = [2, 6]\n",
        "```\n",
        "å®é™…æ•°å€¼å¯èƒ½æ˜¯ï¼š\n",
        "```\n",
        "[\n",
        "  [101, 1045, 2293, 17953, 999, 102],  # \"I love NLP!\" çš„token IDs\n",
        "  [101, 19081, 2024, 3427, 1012, 102]  # \"Transformers are powerful.\" çš„token IDs\n",
        "]\n",
        "```\n",
        "\n",
        "#### 2. æ¨¡å‹è¾“å‡ºçš„éšè—çŠ¶æ€ï¼ˆå‡è®¾éšè—å¤§å°=4ï¼‰\n",
        "```python\n",
        "shape = [batch_size, sequence_length, hidden_size] = [2, 6, 4]\n",
        "```\n",
        "å®é™…è¾“å‡ºå¯èƒ½ç±»ä¼¼ï¼š\n",
        "```python\n",
        "[\n",
        "  # ç¬¬ä¸€ä¸ªå¥å­çš„6ä¸ªtokenï¼Œæ¯ä¸ªtokenç”¨4ç»´å‘é‡è¡¨ç¤º\n",
        "  [[0.1, 0.3, -0.2, 0.8],  # \"[CLS]\" tokençš„è¡¨ç¤º\n",
        "   [0.5, 0.2, 0.6, -0.1],  # \"I\"\n",
        "   [0.3, 0.9, 0.4, 0.7],    # \"love\"\n",
        "   [0.8, 0.5, -0.3, 0.2],   # \"NLP\"\n",
        "   [0.2, 0.1, 0.0, 0.4],    # \"!\"\n",
        "   [0.6, 0.3, 0.1, -0.2]],  # \"[SEP]\"\n",
        "  \n",
        "  # ç¬¬äºŒä¸ªå¥å­çš„6ä¸ªtoken\n",
        "  [[0.1, 0.3, -0.2, 0.8],   # \"[CLS]\"\n",
        "   [0.7, 0.4, 0.9, -0.5],   # \"Transformers\"\n",
        "   [0.2, 0.6, 0.3, 0.1],    # \"are\"\n",
        "   [0.4, 0.8, -0.2, 0.5],   # \"powerful\"\n",
        "   [0.3, 0.1, 0.7, 0.0],    # \".\"\n",
        "   [0.6, 0.3, 0.1, -0.2]]   # \"[SEP]\"\n",
        "]\n",
        "```\n",
        "\n",
        "#### 3. ä¸ºä»€ä¹ˆè¯´\"é«˜ç»´\"ï¼Ÿ\n",
        "- **éšè—å¤§å°=4**ï¼ˆæœ¬ä¾‹ç®€åŒ–å€¼ï¼‰ï¼š\n",
        "  - æ¯ä¸ªtokenè¢«æ˜ å°„åˆ°4ç»´ç©ºé—´çš„ä¸€ä¸ªç‚¹ï¼ˆå¦‚\"love\" â†’ [0.3, 0.9, 0.4, 0.7]ï¼‰\n",
        "  - ç±»ä¼¼ç”¨4ä¸ªç‰¹å¾æè¿°ä¸€ä¸ªtokençš„è¯­ä¹‰\n",
        "  \n",
        "- **å®é™…æ¨¡å‹ï¼ˆå¦‚BERT-baseï¼‰çš„éšè—å¤§å°=768**ï¼š\n",
        "  - æ¯ä¸ªtokenç”¨768ç»´å‘é‡è¡¨ç¤º\n",
        "  - ç›¸å½“äºç”¨768ä¸ªæ•°å€¼ç‰¹å¾ç¼–ç ä¸€ä¸ªtokençš„ä¸Šä¸‹æ–‡ä¿¡æ¯\n",
        "  - ä¾‹å¦‚ï¼š\"bank\"åœ¨\"river bank\"å’Œ\"bank account\"ä¸­ä¼šå¾—åˆ°ä¸åŒçš„768ç»´å‘é‡\n",
        "\n",
        "- **å¤§æ¨¡å‹ï¼ˆå¦‚GPT-3ï¼‰çš„éšè—å¤§å°å¯è¾¾12288**ï¼š\n",
        "  - æ¯ä¸ªtokençš„è¡¨ç¤ºç©ºé—´ç»´åº¦æé«˜\n",
        "  - èƒ½æ•è·æ›´ç»†ç²’åº¦çš„è¯­ä¹‰å’Œè¯­æ³•ç‰¹å¾\n",
        "\n",
        "#### 4. ä¸‰ç»´ç»“æ„çš„å®é™…æ„ä¹‰\n",
        "- **æ‰¹å¤„ç†ç»´åº¦**ï¼šåŒæ—¶å¤„ç†å¤šä¸ªå¥å­ï¼ˆæœ¬ä¾‹2ä¸ªï¼‰\n",
        "- **åºåˆ—ç»´åº¦**ï¼šä¿ç•™æ¯ä¸ªtokençš„ä½ç½®ä¿¡æ¯ï¼ˆæœ¬ä¾‹æ¯ä¸ªå¥å­6ä¸ªtokenï¼‰\n",
        "- **éšè—ç»´åº¦**ï¼šæ¯ä¸ªtokençš„\"çŸ¥è¯†å­˜å‚¨ç©ºé—´\"ï¼Œç»´åº¦è¶Šé«˜è¡¨å¾èƒ½åŠ›è¶Šå¼º\n",
        "\n",
        "---\n",
        "\n",
        "### ç±»æ¯”å¸®åŠ©ç†è§£\n",
        "æŠŠTransformerè¾“å‡ºæƒ³è±¡æˆä¸€ä¸ªç«‹æ–¹ä½“ï¼š\n",
        "```\n",
        "       éšè—å¤§å°ï¼ˆ768ï¼‰\n",
        "       â†‘\n",
        "      / \\\n",
        "     /   \\\n",
        "    â”Œâ”€â”€â”€â”€â”€â”\n",
        "    â”‚     â”‚ â† ä¸€ä¸ªtokençš„è¡¨ç¤ºï¼ˆ768ä¸ªæ•°å€¼ï¼‰\n",
        "    â””â”€â”€â”€â”€â”€â”˜\n",
        "   â†—\n",
        "åºåˆ—é•¿åº¦ï¼ˆ16ï¼‰\n",
        "æ‰¹å¤§å°ï¼ˆ2ï¼‰ â†’ æ•´ä¸ªç«‹æ–¹ä½“åŒ…å« 2Ã—16Ã—768 ä¸ªæ•°å€¼\n",
        "```\n",
        "\n",
        "è¿™ç§é«˜ç»´è¡¨ç¤ºä½¿å¾—æ¨¡å‹èƒ½åŒºåˆ†ï¼š\n",
        "- åŒå½¢å¼‚ä¹‰è¯ï¼š\"è‹¹æœ\"ï¼ˆå…¬å¸ vs æ°´æœï¼‰\n",
        "- å¤æ‚è¯­ä¹‰ï¼š\"è™½ç„¶ä¸‹é›¨äº†ï¼Œä½†æˆ‘å¾ˆå¼€å¿ƒ\"ä¸­çš„æƒ…æ„ŸçŸ›ç›¾"
      ],
      "metadata": {
        "id": "c59bjS5jITSO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformeræ¨¡å‹é€šè¿‡é«˜ç»´éšè—è¡¨ç¤ºï¼ˆå¦‚768ç»´æˆ–æ›´é«˜ï¼‰èƒ½å¤ŸåŒºåˆ†å¤æ‚è¯­ä¹‰ï¼Œè¿™ä¸»è¦ä¾èµ–äºä»¥ä¸‹å‡ ä¸ªå…³é”®æœºåˆ¶ï¼š\n",
        "\n",
        "### 1. **ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„åŠ¨æ€ç¼–ç **\n",
        "   - **ä¼ ç»Ÿè¯å‘é‡é—®é¢˜**ï¼šåƒWord2Vecè¿™æ ·çš„é™æ€åµŒå…¥ä¼šç»™\"è‹¹æœ\"åˆ†é…å›ºå®šå‘é‡ï¼Œæ— æ³•åŒºåˆ†\"è‹¹æœæ‰‹æœº\"å’Œ\"åƒè‹¹æœ\"çš„ä¸åŒå«ä¹‰ã€‚\n",
        "   - **Transformerçš„è§£å†³æ–¹æ¡ˆ**ï¼š\n",
        "     - é€šè¿‡è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œæ¨¡å‹ä¼šæ ¹æ®å¥å­ä¸Šä¸‹æ–‡åŠ¨æ€è°ƒæ•´æ¯ä¸ªtokençš„è¡¨ç¤º\n",
        "     - ç¤ºä¾‹ï¼š\n",
        "       ```python\n",
        "       # \"è‹¹æœ\"åœ¨ä¸åŒè¯­å¢ƒä¸‹çš„å‘é‡å·®å¼‚\n",
        "       è‹¹æœ_å…¬å¸ = [0.8, -0.2, 0.3, ..., 0.6]  # ä¸\"æ‰‹æœº\"\"å‘å¸ƒä¼š\"ç­‰è¯å…³è”\n",
        "       è‹¹æœ_æ°´æœ = [0.3, 0.5, -0.7, ..., 0.1]  # ä¸\"åƒ\"\"ç”œ\"\"æ°´æœ\"ç­‰è¯å…³è”\n",
        "       ```\n",
        "     - ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—å¯èƒ½æ˜¾ç¤ºè¿™ä¸¤ä¸ªå‘é‡çš„ç›¸ä¼¼åº¦ä½äº0.3ï¼ˆå®Œå…¨ç›¸åŒçš„å‘é‡ä¸º1.0ï¼‰\n",
        "\n",
        "### 2. **æ³¨æ„åŠ›æœºåˆ¶çš„å¤šå±‚æ¬¡ç†è§£**\n",
        "   - **ç¬¬ä¸€å±‚æ³¨æ„åŠ›**ï¼ˆå±€éƒ¨è¯­æ³•ï¼‰ï¼š\n",
        "     - \"ä¸‹é›¨\" â†’ \"è™½ç„¶\"ï¼ˆè½¬æŠ˜å…³ç³»ï¼‰\n",
        "     - \"å¼€å¿ƒ\" â†’ \"ä½†\"ï¼ˆæƒ…æ„Ÿè½¬æŠ˜ï¼‰\n",
        "   - **æ·±å±‚æ³¨æ„åŠ›**ï¼ˆè¯­ä¹‰ç»„åˆï¼‰ï¼š\n",
        "     ```python\n",
        "     # æƒ…æ„Ÿåˆ†æä¸­çš„çŸ›ç›¾è¯­ä¹‰å¤„ç†\n",
        "     è™½ç„¶_vec = [0.2, -0.1, ..., 0.9]  # æºå¸¦è½¬æŠ˜é¢„æœŸ\n",
        "     ä¸‹é›¨_vec = [0.7, -0.8, ..., -0.5] # è´Ÿé¢æƒ…æ„Ÿå€¾å‘\n",
        "     ä½†_vec   = [-0.3, 0.6, ..., 0.4]  # å¼ºè½¬æŠ˜ä¿¡å·\n",
        "     å¼€å¿ƒ_vec = [-0.9, 0.7, ..., 0.8]  # æ­£é¢æƒ…æ„Ÿ\n",
        "     \n",
        "     # æ¨¡å‹é€šè¿‡æ³¨æ„åŠ›æƒé‡ç»„åˆï¼š\n",
        "     æœ€ç»ˆè¡¨ç¤º = 0.3*è™½ç„¶_vec + 0.1*ä¸‹é›¨_vec + 0.4*ä½†_vec + 0.9*å¼€å¿ƒ_vec\n",
        "     ```\n",
        "\n",
        "### 3. **é«˜ç»´ç©ºé—´çš„å‡ ä½•ç‰¹æ€§**\n",
        "   - **è¡¨å¾èƒ½åŠ›**ï¼š\n",
        "     - 768ç»´ç©ºé—´å¯ä»¥æ„é€ 10^300+ä¸ªä¸åŒçš„è¶…å¹³é¢ï¼ˆå†³ç­–è¾¹ç•Œï¼‰\n",
        "     - ç›¸æ¯”ä¹‹ä¸‹ï¼Œ50ç»´Word2Vecåªèƒ½æ„é€ çº¦10^15ä¸ªè¶…å¹³é¢\n",
        "   - **è¯­ä¹‰æ‹“æ‰‘ç»“æ„**ï¼š\n",
        "     ```\n",
        "     é«˜ç»´ç©ºé—´ä¸­ï¼š\n",
        "     \"è‹¹æœå…¬å¸\" â€”â€”é è¿‘â€”â€”> \"ç§‘æŠ€\"/\"æ‰‹æœº\"\n",
        "                   â†‘\n",
        "                  (æ­£äº¤è½´)\n",
        "                   â†“\n",
        "     \"è‹¹æœæ°´æœ\" â€”â€”é è¿‘â€”â€”> \"é£Ÿç‰©\"/\"å¥åº·\"\n",
        "     ```\n",
        "\n",
        "### 4. **å±‚çº§ç‰¹å¾æå–**\n",
        "   - **åº•å±‚ï¼ˆé è¿‘è¾“å…¥å±‚ï¼‰**ï¼š\n",
        "     - è¯†åˆ«è¯æ€§/åŸºæœ¬è¯­æ³•ï¼ˆ\"ä¸‹é›¨\"æ˜¯åŠ¨è¯ï¼Œ\"å¼€å¿ƒ\"æ˜¯å½¢å®¹è¯ï¼‰\n",
        "   - **ä¸­å±‚**ï¼š\n",
        "     - æ•æ‰çŸ­è¯­çº§è¯­ä¹‰ï¼ˆ\"ä¸‹é›¨äº†\"â†’è´Ÿé¢ï¼Œ\"å¾ˆå¼€å¿ƒ\"â†’æ­£é¢ï¼‰\n",
        "   - **é«˜å±‚ï¼ˆé è¿‘è¾“å‡ºå±‚ï¼‰**ï¼š\n",
        "     - æ„å»ºå¥å­çº§ç†è§£ï¼ˆè½¬æŠ˜å…³ç³»çš„æ•´ä½“æƒ…æ„Ÿå€¾å‘ï¼‰\n",
        "\n",
        "### 5. **å…·ä½“æ¡ˆä¾‹åˆ†æ\n",
        "#### æ¡ˆä¾‹1ï¼šåŒå½¢å¼‚ä¹‰è¯åŒºåˆ†\n",
        "   ```python\n",
        "   # è¾“å…¥å¥å­1ï¼š\"è‹¹æœå‘å¸ƒäº†æ–°æ‰‹æœº\"\n",
        "   [CLS] è‹¹æœ å‘å¸ƒ äº† æ–° æ‰‹æœº [SEP]\n",
        "   \n",
        "   # è¾“å…¥å¥å­2ï¼š\"æˆ‘ä¹°äº†ä¸€ä¸ªè‹¹æœ\"\n",
        "   [CLS] æˆ‘ ä¹° äº† ä¸€ ä¸ª è‹¹æœ [SEP]\n",
        "   \n",
        "   # æ¨¡å‹å¤„ç†ï¼š\n",
        "   1. \"è‹¹æœ\"çš„åˆå§‹åµŒå…¥ç›¸åŒï¼ˆç›¸åŒçš„token IDï¼‰\n",
        "   2. ç»è¿‡å¤šå±‚Transformeråï¼š\n",
        "      - å¥å­1ä¸­çš„\"è‹¹æœ\"å—åˆ°\"å‘å¸ƒ\"\"æ‰‹æœº\"ç­‰è¯çš„å½±å“â†’å‘é‡åå‘ç§‘æŠ€å…¬å¸\n",
        "      - å¥å­2ä¸­çš„\"è‹¹æœ\"å—åˆ°\"ä¹°\"\"ä¸ª\"ç­‰è¯çš„å½±å“â†’å‘é‡åå‘æ°´æœ\n",
        "   3. æœ€ç»ˆä¸¤è€…çš„ä½™å¼¦ç›¸ä¼¼åº¦å¯èƒ½ï¼œ0.4\n",
        "   ```\n",
        "\n",
        "#### æ¡ˆä¾‹2ï¼šæƒ…æ„ŸçŸ›ç›¾è§£æ\n",
        "   ```python\n",
        "   # è¾“å…¥å¥å­ï¼š\"è™½ç„¶ä¸‹é›¨äº†ï¼Œä½†æˆ‘å¾ˆå¼€å¿ƒ\"\n",
        "   [CLS] è™½ç„¶ ä¸‹é›¨ äº† ï¼Œ ä½† æˆ‘ å¾ˆ å¼€å¿ƒ [SEP]\n",
        "   \n",
        "   # å…³é”®æ­¥éª¤ï¼š\n",
        "   1. æ³¨æ„åŠ›å¤´1å‘ç°ï¼š\"è™½ç„¶\"â†”\"ä½†\"ï¼ˆè½¬æŠ˜å…³ç³»ï¼Œæƒé‡0.8ï¼‰\n",
        "   2. æ³¨æ„åŠ›å¤´2å‘ç°ï¼š\"ä¸‹é›¨\"â†”\"ä¸å¼€å¿ƒ\"ï¼ˆéšå«å…³è”ï¼Œæƒé‡0.6ï¼‰\n",
        "   3. æ³¨æ„åŠ›å¤´3å‘ç°ï¼š\"å¾ˆå¼€å¿ƒ\"â†”\"ä½†\"ï¼ˆæƒ…æ„Ÿå¼ºåŒ–ï¼Œæƒé‡0.9ï¼‰\n",
        "   4. æœ€ç»ˆ[CLS]ä½ç½®æ±‡é›†æ‰€æœ‰ä¿¡æ¯ï¼š\n",
        "      - ç»¼åˆå¾—åˆ†ï¼šæ­£é¢æƒ…æ„Ÿ0.7ï¼Œè´Ÿé¢æƒ…æ„Ÿ0.3\n",
        "      - åˆ†ç±»ç»“æœï¼šæ­£é¢ï¼ˆå°½ç®¡å«æœ‰è´Ÿé¢è¯æ±‡ï¼‰\n",
        "   ```\n",
        "\n",
        "### ä¸ºä»€ä¹ˆä½ç»´è¡¨ç¤ºæ— æ³•åšåˆ°ï¼Ÿ\n",
        "å‡è®¾åªç”¨20ç»´å‘é‡ï¼š\n",
        "- æ— æ³•åŒæ—¶ç¼–ç è¯­æ³•/æƒ…æ„Ÿ/æŒ‡ä»£ç­‰å¤šå±‚æ¬¡ä¿¡æ¯\n",
        "- è¯­ä¹‰ç©ºé—´è¿‡äºæ‹¥æŒ¤ï¼Œä¸åŒå«ä¹‰çš„\"è‹¹æœ\"å‘é‡ä¼šé‡å \n",
        "- éš¾ä»¥å»ºç«‹å¤æ‚çš„è½¬æŠ˜å…³ç³»ï¼ˆéœ€è¦æ›´é«˜ç»´åº¦çš„æ­£äº¤åŸºï¼‰\n",
        "\n",
        "è€Œ768+ç»´ç©ºé—´å¯ä»¥ï¼š\n",
        "- ä¸ºæ¯ä¸ªè¯­ä¹‰ç»´åº¦åˆ†é…ç‹¬ç«‹çš„\"å­ç©ºé—´\"\n",
        "- é€šè¿‡çº¿æ€§å˜æ¢æ„å»ºæ•°ç™¾ä¸‡ä¸ªæ½œåœ¨çš„ç‰¹å¾ç»„åˆ\n",
        "- ä¿æŒä¸åŒå«ä¹‰å‘é‡çš„è¿‘ä¼¼æ­£äº¤æ€§ï¼ˆäº’ä¸å¹²æ‰°ï¼‰\n",
        "\n",
        "è¿™ç§é«˜ç»´åŠ¨æ€ç¼–ç ï¼Œæ­£æ˜¯Transformerç†è§£å¤æ‚è¯­è¨€ç°è±¡çš„æ ¸å¿ƒä¼˜åŠ¿ã€‚"
      ],
      "metadata": {
        "id": "2OZiOR0TI8lw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "9SwigsOtEh4g"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "model = AutoModel.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Bqwwknj4Eh4g",
        "outputId": "a4211054-78bd-436a-df4b-66dc087bca13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 16, 768])\n"
          ]
        }
      ],
      "source": [
        "outputs = model(**inputs)\n",
        "print(outputs.last_hidden_state.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "J2QZoIOwEh4g"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "outputs = model(**inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "wr21DQYHEh4h",
        "outputId": "2795d533-b423-4823-946a-fac79ea1c246",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n"
          ]
        }
      ],
      "source": [
        "print(outputs.logits.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "aEzrYIHxEh4h",
        "outputId": "48e5b009-67e8-4d39-b58a-aff863cbd777",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.5607,  1.6123],\n",
            "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(outputs.logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### æ¨¡å‹è¾“å‡ºçš„åå¤„ç†æ­¥éª¤è§£æ\n",
        "\n",
        "å½“æ¨¡å‹ç›´æ¥è¾“å‡ºåŸå§‹ç»“æœæ—¶ï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡åå¤„ç†ä½¿å…¶å…·æœ‰å¯è§£é‡Šæ€§ã€‚ä»¥ä¸‹æ˜¯å…³é”®æ­¥éª¤çš„è¯¦ç»†è¯´æ˜ï¼š\n",
        "\n",
        "#### 1. ç†è§£åŸå§‹è¾“å‡ºï¼ˆLogitsï¼‰\n",
        "æ¨¡å‹æœ€åä¸€å±‚è¾“å‡ºçš„åŸå§‹åˆ†æ•°ç§°ä¸º**logits**ï¼š\n",
        "```python\n",
        "tensor([[-1.5607,  1.6123],  # ç¬¬ä¸€ä¸ªå¥å­çš„logits\n",
        "        [ 4.1692, -3.3464]]) # ç¬¬äºŒä¸ªå¥å­çš„logits\n",
        "```\n",
        "- è¿™äº›æ•°å€¼æ²¡æœ‰æ¦‚ç‡æ„ä¹‰\n",
        "- æ­£/è´Ÿå€¼ä»…è¡¨ç¤ºç›¸å¯¹ç½®ä¿¡åº¦ï¼ˆå¦‚ç¬¬ä¸€ä¸ªå¥å­ä¸­1.6123 > -1.5607ï¼Œå€¾å‘POSITIVEï¼‰\n",
        "\n",
        "#### 2. è½¬æ¢ä¸ºæ¦‚ç‡ï¼ˆSoftMaxå¤„ç†ï¼‰\n",
        "é€šè¿‡SoftMaxå‡½æ•°å°†logitsè½¬æ¢ä¸ºæ¦‚ç‡åˆ†å¸ƒï¼š\n",
        "```python\n",
        "import torch\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "```\n",
        "è¾“å‡ºç»“æœï¼š\n",
        "```python\n",
        "tensor([[0.0402, 0.9598],  # ç¬¬ä¸€ä¸ªå¥å­çš„æ¦‚ç‡\n",
        "        [0.9995, 0.0005]]) # ç¬¬äºŒä¸ªå¥å­çš„æ¦‚ç‡\n",
        "```\n",
        "- `dim=-1` è¡¨ç¤ºå¯¹æœ€åä¸€ä¸ªç»´åº¦ï¼ˆæ ‡ç­¾ç»´åº¦ï¼‰åšå½’ä¸€åŒ–\n",
        "- æ¯è¡Œä¸¤ä¸ªå€¼çš„å’Œä¸º1ï¼ˆç¬¦åˆæ¦‚ç‡åˆ†å¸ƒç‰¹æ€§ï¼‰\n",
        "\n",
        "#### 3. æ ‡ç­¾æ˜ å°„\n",
        "é€šè¿‡æ¨¡å‹é…ç½®æŸ¥çœ‹æ ‡ç­¾å¯¹åº”å…³ç³»ï¼š\n",
        "```python\n",
        "model.config.id2label  # è¾“å‡º: {0: 'NEGATIVE', 1: 'POSITIVE'}\n",
        "```\n",
        "æœ€ç»ˆé¢„æµ‹ç»“æœï¼š\n",
        "- **ç¬¬ä¸€ä¸ªå¥å­**ï¼š\"I've been waiting...\"  \n",
        "  â†’ POSITIVE (95.98%ç½®ä¿¡åº¦)  \n",
        "- **ç¬¬äºŒä¸ªå¥å­**ï¼š\"I hate this...\"  \n",
        "  â†’ NEGATIVE (99.95%ç½®ä¿¡åº¦)\n",
        "\n",
        "#### æŠ€æœ¯ç»†èŠ‚è¯´æ˜\n",
        "| æ­¥éª¤ | è¾“å…¥ | æ“ä½œ | è¾“å‡º | ç›®çš„ |\n",
        "|------|------|------|------|------|\n",
        "| æ¨¡å‹åŸå§‹è¾“å‡º | æ–‡æœ¬ç‰¹å¾ | çº¿æ€§å±‚ | Logits | è·å¾—åŸå§‹åˆ†æ•° |\n",
        "| SoftMax | Logits | e^x/sum(e^x) | æ¦‚ç‡ | æ•°å€¼å½’ä¸€åŒ– |\n",
        "| æ ‡ç­¾æ˜ å°„ | æ¦‚ç‡ | id2label | æ ‡ç­¾ | äººç±»å¯è¯»ç»“æœ |\n",
        "\n",
        "#### ä¸ºä»€ä¹ˆä½¿ç”¨Logitsè€Œéç›´æ¥è¾“å‡ºæ¦‚ç‡ï¼Ÿ\n",
        "1. **è®­ç»ƒæ•ˆç‡**ï¼š  \n",
        "   äº¤å‰ç†µæŸå¤±å‡½æ•°ä¼šåˆå¹¶SoftMaxè®¡ç®—ï¼Œå‡å°‘æ•°å€¼è®¡ç®—æ­¥éª¤\n",
        "2. **æ•°å€¼ç¨³å®šæ€§**ï¼š  \n",
        "   åœ¨åå‘ä¼ æ’­æ—¶ç›´æ¥å¤„ç†logitså¯é¿å…æ¢¯åº¦æ¶ˆå¤±é—®é¢˜\n",
        "3. **çµæ´»æ€§**ï¼š  \n",
        "   æ–¹ä¾¿åç»­æ¥ä¸åŒçš„æŸå¤±å‡½æ•°ï¼ˆå¦‚å¸¦æƒé‡çš„äº¤å‰ç†µï¼‰\n",
        "\n",
        "#### å¯è§†åŒ–ç†è§£\n",
        "```\n",
        "åŸå§‹æ–‡æœ¬ â†’ [Tokenization] â†’ æ¨¡å‹å¤„ç† â†’ Logits â†’ SoftMax â†’ æ¦‚ç‡ â†’ æ ‡ç­¾æ˜ å°„\n",
        "           (é¢„å¤„ç†)        (å‰å‘ä¼ æ’­)  ([-1.56,1.61]) â†’ [0.04,0.96] â†’ \"POSITIVE\"\n",
        "```\n",
        "\n",
        "é€šè¿‡è¿™ä¸‰ä¸ªæ­¥éª¤ï¼Œæˆ‘ä»¬å®Œæ•´å¤ç°äº†pipelineçš„å·¥ä½œæµç¨‹ã€‚è¿™ç§æ¨¡å—åŒ–è®¾è®¡æ—¢ä¿è¯äº†çµæ´»æ€§ï¼ˆå¯å•ç‹¬è°ƒæ•´ä»»ä¸€æ­¥éª¤ï¼‰ï¼Œåˆç¡®ä¿äº†ç»“æœçš„å¯è§£é‡Šæ€§ã€‚"
      ],
      "metadata": {
        "id": "o8LvOOn9KJM5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "yRA308TwEh4i",
        "outputId": "72ca1f85-e9b3-4176-8f4a-bc3b26ed32a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.0195e-02, 9.5980e-01],\n",
            "        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "DKHqSbGxEh4i",
        "outputId": "c7bbd6e4-67e6-4ff3-a775-39c259679231",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'NEGATIVE', 1: 'POSITIVE'}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "model.config.id2label"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Behind the pipeline (PyTorch)",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}