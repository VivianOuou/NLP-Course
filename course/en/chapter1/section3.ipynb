{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2_Sle7DOpOR"
      },
      "source": [
        "# Transformers, what can they do?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCtLpU1POpOS"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nCyXE749OpOS",
        "outputId": "f91f4a0f-5745-4453-d390-32e41ac4c3b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.11/dist-packages (4.50.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (0.5.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (0.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (5.29.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "wZeQBY0iOpOT",
        "outputId": "2de1c0ef-393d-4ff1-d7f2-90912afe5782",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598049521446228}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ut4FDpBfOpOU",
        "outputId": "6551bb3e-c289-4d3d-e0c1-269496df0b92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
              " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "classifier(\n",
        "    [\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this so much!\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "score表示置信度，是模型对情感分类结果的可信度量化，数值越高，表示模型越确信自己的判断"
      ],
      "metadata": {
        "id": "LFfXaE0qPhTV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "0MI1ugKaOpOU",
        "outputId": "0c6dc0c7-59a5-4a04-c0d8-69f86893f886",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'This is a course about the Transformers library',\n",
              " 'labels': ['education', 'business', 'politics'],\n",
              " 'scores': [0.8445994257926941, 0.11197380721569061, 0.04342673346400261]}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "classifier(\n",
        "    \"This is a course about the Transformers library\",\n",
        "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(\n",
        "    \"I want to play at the afternoon.\",\n",
        "    candidate_labels=[\"education\", \"entertaimnet\", \"business\"],\n",
        ")"
      ],
      "metadata": {
        "id": "V-YrFhA6Qpk9",
        "outputId": "0d4681ee-9f1d-49a4-8156-c1e01494048d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'I want to play at the afternoon.',\n",
              " 'labels': ['entertaimnet', 'business', 'education'],\n",
              " 'scores': [0.920432984828949, 0.0464714840054512, 0.03309548646211624]}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "iSqqPeRsOpOU",
        "outputId": "48610e62-6683-49bf-ffab-239d097e5d25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'In this course, we will teach you how to develop a strong, solid, positive mindset of supporting your family.\\n\\n2. Become a Teacher\\n\\nAt this point, I am looking for what skills are needed as a school teacher. We'}]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\")\n",
        "generator(\"In this course, we will teach you how to\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Mg0jBtRxOpOV",
        "outputId": "99e78335-9fc6-457b-958a-8580f1293835",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'In this course, we will teach you how to master the art of drawing.\\n\\n- Learn how to understand, adapt, and read from the'},\n",
              " {'generated_text': 'In this course, we will teach you how to generate a beautiful and simple, intuitive model of the human experience using a natural way of using our visual'}]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "generator(\n",
        "    \"In this course, we will teach you how to\",\n",
        "    max_length=30,\n",
        "    num_return_sequences=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 加载中文文本生成模型\n",
        "generator = pipeline(\"text-generation\", model=\"uer/gpt2-chinese-cluecorpussmall\")\n",
        "\n",
        "# 输入中文提示生成文本\n",
        "output = generator(\n",
        "    \"在这个课程中，我们将教你如何\",\n",
        "    max_length=50,  # 设置生成文本的最大长度\n",
        "    num_return_sequences=2,  # 生成两条结果\n",
        ")\n",
        "\n",
        "# 打印生成的文本\n",
        "for i, result in enumerate(output):\n",
        "    print(f\"生成结果 {i+1}: {result['generated_text']}\")"
      ],
      "metadata": {
        "id": "rdD14vykRe31",
        "outputId": "806239b0-9c3f-491e-ac4a-af3a00b1cf99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "生成结果 1: 在这个课程中，我们将教你如何 解 决 一 个 人 与 人 之 间 「 信 任 危 机 」 教 授 是 一 位 英 国 皇 家 教 育 学 院 的 教 授 ， 对 学\n",
            "生成结果 2: 在这个课程中，我们将教你如何 招 聘 会 主 席 兼 董 事 长 ， 上 下 九 分 讲 师 ！ 由 本 人 于 1999 年 第 一 期 （ 现 位 于 广 州 市 番\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "生成文本当中貌似有一些问题，就是句子并不完整"
      ],
      "metadata": {
        "id": "03UNK9wwSFiL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "-oO-46inOpOW",
        "outputId": "7bfc4db0-97e3-4f2a-e80c-4500f3452e0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilroberta-base and revision fb53ab8 (https://huggingface.co/distilbert/distilroberta-base).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.19198468327522278,\n",
              "  'token': 30412,\n",
              "  'token_str': ' mathematical',\n",
              "  'sequence': 'This course will teach you all about mathematical models.'},\n",
              " {'score': 0.042092032730579376,\n",
              "  'token': 38163,\n",
              "  'token_str': ' computational',\n",
              "  'sequence': 'This course will teach you all about computational models.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "unmasker = pipeline(\"fill-mask\")\n",
        "unmasker(\"This course will teach you all about <mask> models.\", top_k=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 加载 bert-base-cased 模型\n",
        "unmasker = pipeline(\"fill-mask\", model=\"bert-base-cased\")\n",
        "\n",
        "# 输入调整后的句子\n",
        "results = unmasker(\"This course will teach you all about [MASK] models.\", top_k=2)\n",
        "\n",
        "# 打印结果\n",
        "for result in results:\n",
        "    print(result)"
      ],
      "metadata": {
        "id": "2hH_IkFbSxjY",
        "outputId": "3ad89a77-51b5-4baa-9f40-810ab490ea8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'score': 0.2596322000026703, 'token': 1648, 'token_str': 'role', 'sequence': 'This course will teach you all about role models.'}\n",
            "{'score': 0.09427239000797272, 'token': 1103, 'token_str': 'the', 'sequence': 'This course will teach you all about the models.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "结果分析：\n",
        "bert-base-cased 预测的前两个候选词可能是 different 和 new，具体得分和词语可能因模型版本或环境略有不同。\n",
        "与默认模型（预测 mathematical 和 computational）相比，bert-base-cased 的预测更倾向于通用形容词，因为它是一个通用预训练模型，未针对特定领域优化。"
      ],
      "metadata": {
        "id": "YFpKIS70S_Gh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NER 任务：\n",
        "目标是识别文本中的命名实体，并标注其类别（如人名 PER、组织 ORG、地点 LOC）。\n",
        "输出包括实体的词、类别、置信度（score）、以及在句子中的起始和结束位置。\n",
        "\n",
        "grouped_entities=True：\n",
        "默认情况下，NER 模型可能会将多词实体（如“Hugging Face”）拆分成单独的 token（“Hugging”和“Face”）。\n",
        "设置 grouped_entities=True 后，管道会将这些部分重新组合为一个完整的实体。"
      ],
      "metadata": {
        "id": "VOSGzdZPTvKV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "3UZFrV3mOpOW",
        "outputId": "5e2cfa83-2cd0-409c-c3e0-736462ed32ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': np.float32(0.9981694),\n",
              "  'word': 'Sylvain',\n",
              "  'start': 11,\n",
              "  'end': 18},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': np.float32(0.9796019),\n",
              "  'word': 'Hugging Face',\n",
              "  'start': 33,\n",
              "  'end': 45},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': np.float32(0.9932106),\n",
              "  'word': 'Brooklyn',\n",
              "  'start': 49,\n",
              "  'end': 57}]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ner = pipeline(\"ner\", grouped_entities=True)\n",
        "ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#POS 标注每个词的语法功能（如名词、动词）。\n",
        "from transformers import pipeline\n",
        "\n",
        "# 加载 POS 模型\n",
        "pos = pipeline(\"token-classification\", model=\"vblagoje/bert-english-uncased-finetuned-pos\")\n",
        "\n",
        "# 输入句子\n",
        "results = pos(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")\n",
        "\n",
        "# 打印结果\n",
        "for result in results:\n",
        "    print(result)"
      ],
      "metadata": {
        "id": "zq0MJlZjTkgC",
        "outputId": "f1d80b75-a910-4492-86c1-aa4d3c1cee9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'entity': 'PRON', 'score': np.float32(0.9994592), 'index': 1, 'word': 'my', 'start': 0, 'end': 2}\n",
            "{'entity': 'NOUN', 'score': np.float32(0.99601364), 'index': 2, 'word': 'name', 'start': 3, 'end': 7}\n",
            "{'entity': 'AUX', 'score': np.float32(0.9953696), 'index': 3, 'word': 'is', 'start': 8, 'end': 10}\n",
            "{'entity': 'PROPN', 'score': np.float32(0.99848914), 'index': 4, 'word': 'sy', 'start': 11, 'end': 13}\n",
            "{'entity': 'PROPN', 'score': np.float32(0.9978808), 'index': 5, 'word': '##lva', 'start': 13, 'end': 16}\n",
            "{'entity': 'PROPN', 'score': np.float32(0.99808747), 'index': 6, 'word': '##in', 'start': 16, 'end': 18}\n",
            "{'entity': 'CCONJ', 'score': np.float32(0.99918765), 'index': 7, 'word': 'and', 'start': 19, 'end': 22}\n",
            "{'entity': 'PRON', 'score': np.float32(0.9994679), 'index': 8, 'word': 'i', 'start': 23, 'end': 24}\n",
            "{'entity': 'VERB', 'score': np.float32(0.99923587), 'index': 9, 'word': 'work', 'start': 25, 'end': 29}\n",
            "{'entity': 'ADP', 'score': np.float32(0.9063111), 'index': 10, 'word': 'at', 'start': 30, 'end': 32}\n",
            "{'entity': 'PROPN', 'score': np.float32(0.7182432), 'index': 11, 'word': 'hugging', 'start': 33, 'end': 40}\n",
            "{'entity': 'PROPN', 'score': np.float32(0.71986103), 'index': 12, 'word': 'face', 'start': 41, 'end': 45}\n",
            "{'entity': 'ADP', 'score': np.float32(0.9993789), 'index': 13, 'word': 'in', 'start': 46, 'end': 48}\n",
            "{'entity': 'PROPN', 'score': np.float32(0.9989513), 'index': 14, 'word': 'brooklyn', 'start': 49, 'end': 57}\n",
            "{'entity': 'PUNCT', 'score': np.float32(0.99963903), 'index': 15, 'word': '.', 'start': 57, 'end': 58}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ncx9pTBROpOX",
        "outputId": "d8acbc75-6c4e-4e35-e42f-bad38b673f13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.6949766278266907, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "#这个是提取式问答，并不是生成答案（与gpt的不同之处）\n",
        "question_answerer = pipeline(\"question-answering\")\n",
        "question_answerer(\n",
        "    question=\"Where do I work?\",\n",
        "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "lEatXFd7OpOX",
        "outputId": "c25fe6da-76dd-47cc-8cd7-2068d0e21b0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': ' America has changed dramatically during recent years . The number of engineering graduates in the U.S. has declined in traditional engineering disciplines such as mechanical, civil,    electrical, chemical, and aeronautical engineering . Rapidly developing economies such as China and India continue to encourage and advance the teaching of engineering .'}]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\")\n",
        "summarizer(\n",
        "    \"\"\"\n",
        "    America has changed dramatically during recent years. Not only has the number of\n",
        "    graduates in traditional engineering disciplines such as mechanical, civil,\n",
        "    electrical, chemical, and aeronautical engineering declined, but in most of\n",
        "    the premier American universities engineering curricula now concentrate on\n",
        "    and encourage largely the study of engineering science. As a result, there\n",
        "    are declining offerings in engineering subjects dealing with infrastructure,\n",
        "    the environment, and related issues, and greater concentration on high\n",
        "    technology subjects, largely supporting increasingly complex scientific\n",
        "    developments. While the latter is important, it should not be at the expense\n",
        "    of more traditional engineering.\n",
        "\n",
        "    Rapidly developing economies such as China and India, as well as other\n",
        "    industrial countries in Europe and Asia, continue to encourage and advance\n",
        "    the teaching of engineering. Both China and India, respectively, graduate\n",
        "    six and eight times as many traditional engineers as does the United States.\n",
        "    Other industrial countries at minimum maintain their output, while America\n",
        "    suffers an increasingly serious decline in the number of engineering graduates\n",
        "    and a lack of well-educated engineers.\n",
        "\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Xf05muHbOpOY",
        "outputId": "24fce602-aa4f-4b5b-bc1c-7ece586f0c8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'translation_text': 'This course is produced by Hugging Face.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
        "translator(\"Ce cours est produit par Hugging Face.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 法语到英语\n",
        "translator_fr_en = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
        "text_en = translator_fr_en(\"Ce cours est produit par Hugging Face.\")[0][\"translation_text\"]\n",
        "\n",
        "# 英语到中文\n",
        "translator_en_zh = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-zh\")\n",
        "text_zh = translator_en_zh(text_en)[0][\"translation_text\"]\n",
        "\n",
        "print(text_zh)\n",
        "\n",
        "#如果直接法语到中文，是会报错的，需要法语-英文-中文"
      ],
      "metadata": {
        "id": "W_UVsTeiU_6-",
        "outputId": "930aab5e-6ed1-40ab-99aa-b7f8a3e8971b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "这门课程由Huggging Face制作。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "对于这一节课的总结：\n",
        "学习了pipeline里面设置的很多方法\n",
        "对于一个句子的语义分析打分，对于一个句子贴标签的打分（直接用预训练模型），文本生成（感觉这个生成的质量一般般，特别是对于中文，同时有时候生成不了完整的句子），填充句子中的空白（其实是短语的提炼和训练），识别句子中的人名地名 or 动名词之类的，根据提供的文本回答问题，总结问题，翻译句子（但是好像需要用英文来作为媒介）"
      ],
      "metadata": {
        "id": "3SMVarlNVhxX"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Transformers, what can they do?",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}